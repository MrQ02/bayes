<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Improvements on Neural Networks | Recurrent Neural Networks</title>
  <meta name="description" content="A mini bookdown tutorial book on how to make bookdown books." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Improvements on Neural Networks | Recurrent Neural Networks" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A mini bookdown tutorial book on how to make bookdown books." />
  <meta name="github-repo" content="openscapes/series" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Improvements on Neural Networks | Recurrent Neural Networks" />
  
  <meta name="twitter:description" content="A mini bookdown tutorial book on how to make bookdown books." />
  

<meta name="author" content="Julie Lowndes" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basics.html"/>
<link rel="next" href="cnn.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Mini Bookdown Tutorial</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Deep Learning</a></li>
<li class="chapter" data-level="2" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>2</b> Basics of Neural Networks</a>
<ul>
<li class="chapter" data-level="2.1" data-path="basics.html"><a href="basics.html#neural-network-representation"><i class="fa fa-check"></i><b>2.1</b> Neural Network Representation</a></li>
<li class="chapter" data-level="2.2" data-path="basics.html"><a href="basics.html#activation-functions"><i class="fa fa-check"></i><b>2.2</b> Activation Functions</a></li>
<li class="chapter" data-level="2.3" data-path="basics.html"><a href="basics.html#training"><i class="fa fa-check"></i><b>2.3</b> Training</a></li>
<li class="chapter" data-level="2.4" data-path="basics.html"><a href="basics.html#gradient-descent"><i class="fa fa-check"></i><b>2.4</b> Gradient Descent</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="imp.html"><a href="imp.html"><i class="fa fa-check"></i><b>3</b> Improvements on Neural Networks</a>
<ul>
<li class="chapter" data-level="3.1" data-path="imp.html"><a href="imp.html#traintest-split"><i class="fa fa-check"></i><b>3.1</b> Train/Test Split</a></li>
<li class="chapter" data-level="3.2" data-path="imp.html"><a href="imp.html#initialization"><i class="fa fa-check"></i><b>3.2</b> Initialization</a></li>
<li class="chapter" data-level="3.3" data-path="imp.html"><a href="imp.html#data-fitting"><i class="fa fa-check"></i><b>3.3</b> Data Fitting</a></li>
<li class="chapter" data-level="3.4" data-path="imp.html"><a href="imp.html#regularization"><i class="fa fa-check"></i><b>3.4</b> Regularization</a></li>
<li class="chapter" data-level="3.5" data-path="imp.html"><a href="imp.html#optimization"><i class="fa fa-check"></i><b>3.5</b> Optimization</a></li>
<li class="chapter" data-level="3.6" data-path="imp.html"><a href="imp.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>3.6</b> Hyperparameter Tuning</a></li>
<li class="chapter" data-level="3.7" data-path="imp.html"><a href="imp.html#batch-normalization"><i class="fa fa-check"></i><b>3.7</b> Batch Normalization</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cnn.html"><a href="cnn.html"><i class="fa fa-check"></i><b>4</b> Convolutional Neural Networks</a>
<ul>
<li class="chapter" data-level="4.1" data-path="cnn.html"><a href="cnn.html#basics-of-cnn"><i class="fa fa-check"></i><b>4.1</b> Basics of CNN</a></li>
<li class="chapter" data-level="4.2" data-path="cnn.html"><a href="cnn.html#cnn-examples"><i class="fa fa-check"></i><b>4.2</b> CNN Examples</a></li>
<li class="chapter" data-level="4.3" data-path="cnn.html"><a href="cnn.html#object-detection"><i class="fa fa-check"></i><b>4.3</b> Object Detection</a></li>
<li class="chapter" data-level="4.4" data-path="cnn.html"><a href="cnn.html#face-recognition"><i class="fa fa-check"></i><b>4.4</b> Face Recognition</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="rnn.html"><a href="rnn.html"><i class="fa fa-check"></i><b>5</b> Recurrent Neural Networks</a>
<ul>
<li class="chapter" data-level="5.1" data-path="rnn.html"><a href="rnn.html#basics-of-rnn"><i class="fa fa-check"></i><b>5.1</b> Basics of RNN</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="rnn.html"><a href="rnn.html#intuition-of-sequence-models"><i class="fa fa-check"></i><b>5.1.1</b> <strong>Intuition of Sequence Models</strong></a></li>
<li class="chapter" data-level="5.1.2" data-path="rnn.html"><a href="rnn.html#intuition-of-rnn"><i class="fa fa-check"></i><b>5.1.2</b> <strong>Intuition of RNN</strong></a></li>
<li class="chapter" data-level="5.1.3" data-path="rnn.html"><a href="rnn.html#rnn-types"><i class="fa fa-check"></i><b>5.1.3</b> <strong>RNN Types</strong></a></li>
<li class="chapter" data-level="5.1.4" data-path="rnn.html"><a href="rnn.html#language-model"><i class="fa fa-check"></i><b>5.1.4</b> <strong>Language Model</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="rnn.html"><a href="rnn.html#rnn-variations"><i class="fa fa-check"></i><b>5.2</b> RNN Variations</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="rnn.html"><a href="rnn.html#gru-gated-recurrent-unit"><i class="fa fa-check"></i><b>5.2.1</b> <strong>GRU</strong> (Gated Recurrent Unit)</a></li>
<li class="chapter" data-level="5.2.2" data-path="rnn.html"><a href="rnn.html#lstm-long-short-term-memory"><i class="fa fa-check"></i><b>5.2.2</b> <strong>LSTM</strong> (Long Short-Term Memory)</a></li>
<li class="chapter" data-level="5.2.3" data-path="rnn.html"><a href="rnn.html#bidirectional-rnn"><i class="fa fa-check"></i><b>5.2.3</b> <strong>Bidirectional RNN</strong></a></li>
<li class="chapter" data-level="5.2.4" data-path="rnn.html"><a href="rnn.html#deep-rnn"><i class="fa fa-check"></i><b>5.2.4</b> <strong>Deep RNN</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="rnn.html"><a href="rnn.html#word-embeddings"><i class="fa fa-check"></i><b>5.3</b> Word Embeddings</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="rnn.html"><a href="rnn.html#featurized-representation"><i class="fa fa-check"></i><b>5.3.1</b> <strong>Featurized Representation</strong></a></li>
<li class="chapter" data-level="5.3.2" data-path="rnn.html"><a href="rnn.html#learning-1-word2vec"><i class="fa fa-check"></i><b>5.3.2</b> Learning 1: <strong>Word2Vec</strong></a></li>
<li class="chapter" data-level="5.3.3" data-path="rnn.html"><a href="rnn.html#learning-2-negative-sampling"><i class="fa fa-check"></i><b>5.3.3</b> Learning 2: <strong>Negative Sampling</strong></a></li>
<li class="chapter" data-level="5.3.4" data-path="rnn.html"><a href="rnn.html#learning-3-glove-global-vectors"><i class="fa fa-check"></i><b>5.3.4</b> Learning 3: <strong>GloVe</strong> (Global Vectors)</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="rnn.html"><a href="rnn.html#sequence-modeling"><i class="fa fa-check"></i><b>5.4</b> Sequence Modeling</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="rnn.html"><a href="rnn.html#sentiment-classification"><i class="fa fa-check"></i><b>5.4.1</b> <strong>Sentiment Classification</strong></a></li>
<li class="chapter" data-level="5.4.2" data-path="rnn.html"><a href="rnn.html#seq2seq"><i class="fa fa-check"></i><b>5.4.2</b> <strong>Seq2Seq</strong></a></li>
<li class="chapter" data-level="5.4.3" data-path="rnn.html"><a href="rnn.html#beam-search"><i class="fa fa-check"></i><b>5.4.3</b> <strong>Beam Search</strong></a></li>
<li class="chapter" data-level="5.4.4" data-path="rnn.html"><a href="rnn.html#bleu-score"><i class="fa fa-check"></i><b>5.4.4</b> <strong>Bleu Score</strong></a></li>
<li class="chapter" data-level="5.4.5" data-path="rnn.html"><a href="rnn.html#attention-model"><i class="fa fa-check"></i><b>5.4.5</b> <strong>Attention Model</strong></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Recurrent Neural Networks</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="imp" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Improvements on Neural Networks</h1>
<div id="traintest-split" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Train/Test Split</h2>
<ul>
<li>Dataset = training set + development/validation set + test set</li>
<li>Split ratio:
<ul>
<li>old era: 70/0/30%, 60/20/20%, …</li>
<li>big data era: 98/1/1%, 99.5/0.4/0.1%, 99.5/0.5/0%, … \
(trend: testset as small as possible)</li>
</ul></li>
<li>All 3 subsets should come from the exact same distribution (<strike>mismatch<strike>)</li>
</ul>
</div>
<div id="initialization" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Initialization</h2>
<ul>
<li><span class="math inline">\(W\)</span> should be initialized with <strong>small random values</strong> to break symmetry (to make sure that different hidden nodes can learn different things)</li>
<li><span class="math inline">\(b\)</span> can be initialized to <strong>zeros</strong> (<span class="math inline">\(\because\)</span> symmetry is still broken when <span class="math inline">\(W\)</span> is randomly initialized)</li>
<li>Different initializations <span class="math inline">\(\rightarrow\)</span> different results</li>
<li>Refer to <a href="https://keras.io/initializers/">keras documentation</a> for initializers.</li>
</ul>
</div>
<div id="data-fitting" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Data Fitting</h2>
<p><strong>Underfitting</strong>:</p>
<center>
<img src="../../images/DL/uf.png" width="300"/>
</center>
<p><strong>Proper fitting</strong>:</p>
<center>
<img src="../../images/DL/nof.png" width="300"/>
</center>
<p><strong>Overfitting</strong>:</p>
<center>
<img src="../../images/DL/of.png" width="300"/>
</center>
<p> </p>
<p>Tradeoff: <em>train error</em> vs <em>validation error</em>:
- <strong><em>train err</em> too small <span class="math inline">\(\longrightarrow\)</span> high variance (overfitting)</strong><br />
(e.g. train err = 1%; val err = 11%)
- <strong><em>train err</em> too big <span class="math inline">\(\longrightarrow\)</span> high bias (underfitting)</strong><br />
(e.g. train err = 17%; val err = 16%)
- <strong><em>train err</em> too big &amp; <em>val err</em> even bigger <span class="math inline">\(\longrightarrow\)</span> both probs</strong><br />
(e.g. train err = 17%; val err = 34%)
- <strong><em>train err</em> too small &amp; <em>val err</em> also small <span class="math inline">\(\longrightarrow\)</span> congratulations!</strong><br />
(e.g. train err = 0.5%; val err = 1%)
 <br />
 </p>
<p><a name="pro"></a>
<strong>The Procedure</strong>:</p>
<center>
<img src="../../images/DL/fit.png" width="500"/>
</center>
</div>
<div id="regularization" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Regularization</h2>
<p>Idea: add a regularization term to the original loss function:</p>
<p><span class="math display">\[\begin{equation}
\mathcal{J}(w,b)=\frac{1}{m}\sum_{i=1}^{m}{\mathcal{L}(\hat{y}^{(i)},y^{(i)})}+\frac{\lambda}{2m}f(w)
\end{equation}\]</span></p>
<ul>
<li><span class="math inline">\(\lambda\)</span>: regularization parameter</li>
<li><span class="math inline">\(f(w)\)</span>: regularization on <span class="math inline">\(w\)</span></li>
</ul>
<p>How does regularization prevent overfitting?</p>
<ul>
<li>set <span class="math inline">\(\lambda\)</span> as big as possible <span class="math inline">\(\Rightarrow w^{[l]}\approx 0\)</span> <span class="math inline">\(\Rightarrow z^{[l]}\approx 0\)</span> <span class="math inline">\(\Rightarrow\)</span> as if some hidden nodes don’t exist any more</li>
<li><span class="math inline">\(\Rightarrow\)</span> less complexity <span class="math inline">\(\Rightarrow\)</span> variance <span class="math inline">\(\downarrow\)</span></li>
</ul>
<p> <br />
<strong>Regularization on LogReg</strong>:
- <a name="L2"></a><strong>L2 Regularization</strong>:</p>
<p><span class="math display">\[\begin{equation}
\mathcal{J}(w,b)=\frac{1}{m}\sum_{i=1}^{m}{\mathcal{L}(\hat{y}^{(i)},y^{(i)})}+\frac{\lambda}{2m}\|w\|^2_2 \\
\|w\|^2_2=\sum_{j=1}^{n_x}w_j^2=w^Tw
\end{equation}\]</span></p>
<ul>
<li><a name="L1"></a><strong>L1 Regularization</strong>:</li>
</ul>
<p><span class="math display">\[\begin{equation}
\mathcal{J}(w,b)=\frac{1}{m}\sum_{i=1}^{m}{\mathcal{L}(\hat{y}^{(i)},y^{(i)})}+\frac{\lambda}{2m}\|w\|_1 \\
\|w\|_1=\sum_{j=1}^{n_x}{|w|}
\end{equation}\]</span></p>
<p><a name="nnreg"></a><strong>Regularization on NN</strong>:</p>
<p><span class="math display">\[\begin{equation}
\mathcal{J}(W^{[k]},b^{[k]})=\frac{1}{m}\sum_{i=1}^{m}{\mathcal{L}(\hat{y}^{(i)},y^{(i)})}+\frac{\lambda}{2m}\sum_{l=1}^L{\|W^{[l]}\|^2_F}
\end{equation}\]</span></p>
<ul>
<li>Frobenius Norm:</li>
</ul>
<p><span class="math display">\[\begin{equation}
\|W^{[l]}\|^2_F=\sum_{i=1}^{n_{l-1}}\sum_{j=1}^{n_l}{(w_{ij}^{[l]})^2}
\end{equation}\]</span></p>
<ul>
<li>Weight Decay on GD:</li>
</ul>
<p><span class="math display">\[\begin{align}
W^{[l]}&amp;:=w^{[l]}-\alpha\cdot\frac{\partial{\mathcal{L}}}{\partial{W^{[l]}}} \\
&amp;=w^{[l]}-\alpha\cdot\Big(\frac{\partial{\mathcal{L}}}{\partial{W^{[l]}}}(\text{original})+\frac{\lambda}{m}W^{[l]}\Big)
\end{align}\]</span></p>
<p> <br />
<a name="dp"></a><strong>Dropout</strong>: each node has a probability to be kicked out of the NN (<span class="math inline">\(\Rightarrow\)</span> NN becomes smaller &amp; simpler) <span class="math display">\[only used in training\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Make a <strong>Boolean</strong> matrix corresponding to the matrix of activation values:</p>
<p><span class="math display">\[\begin{align}
 A^{[k]}&amp;=\begin{bmatrix}
 a_{11}^{[k]} &amp; \cdots &amp; a_{1m}^{[k]} \\
 \vdots &amp; \ddots &amp; \vdots \\ 
 a_{n_k1}^{[k]} &amp; \cdots &amp; a_{n_km}^{[k]}
 \end{bmatrix}\quad\quad\quad A^{[k]}\in\mathbb{R}^{n_k\times m} \\ \\
 B^{[k]}&amp;=\begin{bmatrix}
 b_{11}^{[k]} &amp; \cdots &amp; b_{1m}^{[k]} \\
 \vdots &amp; \ddots &amp; \vdots \\ 
 b_{n_k1}^{[k]} &amp; \cdots &amp; b_{n_km}^{[k]}
 \end{bmatrix}\quad\quad\quad B^{[k]}\in\mathbb{R}^{n_k\times m}
 \end{align}\]</span></p>
<p>where <span class="math inline">\(b_{ji}^{[k]}\in\\{\text{True}, \text{False}\\}\)</span>. The Boolean values are assigned randomly based on a keep-probability <span class="math inline">\(p\)</span> (can be chosen differently for diff layers).<br />
</p></li>
<li><p>Multiply both matrices element-wise:</p>
<p><span class="math display">\[\begin{equation}
 A^{[k]}=A^{[k]}* B^{[k]}
 \end{equation}\]</span></p>
<p>so that some activation values are now zero (they are kicked out of the neural network)</p></li>
<li><p>Invert the matrix element-wise:</p>
<p><span class="math display">\[\begin{equation}
 A^{[k]}=A^{[k]}/p
 \end{equation}\]</span></p>
<p>to ensure consistency in activation values</p></li>
</ol>
<p><br/>
<a name="da"></a><strong>Data Augmentation</strong>: modify the dataset to get more data (mostly used in Computer Vision) <span class="math display">\[Benefit: a very low-cost regularization\]</span></p>
<p>Examples:
- flip picture
- slight rotation
- zoom in/out
- distortions
- …</p>
<p><br/>
<a name="da"></a><strong>Early Stopping</strong>: stop the training iterations in the middle</p>
<p>Why do we stop in the middle?</p>
<center>
<img src="../../images/DL/es.png" width="400"/>
</center>
<p>The goal of our training is NOT to finish training BUT to find the optimal weight parameters that minimizes the cost/error.</p>
<p>As shown in the figure, sometimes we should just stop in the middle with the minimal validation error instead of keeping the training going to get overfitting.</p>
<p><br/>
<a name="og"></a><strong>Orthogonalization</strong>: implement controls that only affect <strong>ONE single component</strong> of your algorithms performance at a time</p>
<p><br/>
<a name="norm"></a><strong>Feature Scaling (normalization)</strong>: normalize inputs for higher efficiency</p>
<ol style="list-style-type: decimal">
<li><p>Set to zero mean:</p>
<p><span class="math display">\[\begin{align}
 \mu&amp;=\frac{1}{m}\sum_{i=1}^{m}{x^{(i)}} \\
 x&amp;=x-\mu
 \end{align}\]</span></p></li>
<li><p>Normalize variance:</p>
<p><span class="math display">\[\begin{align}
 \sigma^2&amp;=\frac{1}{m}\sum_{i=1}^{m}{x^{(i)}\text{**}2}\quad\quad \text{**: element-wise squaring} \\
 x&amp;=x/\sigma^2
 \end{align}\]</span></p></li>
</ol>
<p><br/>
<a name="gc"></a><strong>Gradient Checking</strong></p>
<ul>
<li><p>Why?</p>
<p>Backprop is a very complex system of mathematical computations. It is very possible that there might be some miscalculation or bugs in these tremendous differentiations, even though the entire training appears as if it’s working properly.</p>
<p>Gradient Checking is the approach to prevent such issue by checking if each gradient is calculated properly.</p></li>
<li><p>Equation</p>
<p><span class="math display">\[\begin{equation}
  \frac{\partial{\mathcal{J}}}{\partial{w}}=\lim_{\varepsilon\rightarrow 0}\frac{\mathcal{J}(w+\varepsilon)-\mathcal{J}(w-\varepsilon)}{2\varepsilon}\approx\frac{\mathcal{J}(w+\varepsilon)-\mathcal{J}(w-\varepsilon)}{2\varepsilon}
  \end{equation}\]</span></p></li>
<li><p>Implementation: Calculate the difference between actual gradient and approximated gradient to see if the difference is reasonable:</p>
<p><span class="math display">\[\begin{equation}
  \text{diff}=\frac{||g-g&#39;||_ 2}{||g||_ 2+||g&#39;||_ 2}
  \end{equation}\]</span></p></li>
</ul>
</div>
<div id="optimization" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Optimization</h2>
<p><a name="mbgd"></a>
<strong>Mini-Batch Gradient Descent</strong></p>
<ul>
<li><p>Why?</p>
<p>To allow faster and more efficient computing when there is a large number of training examples (e.g. <span class="math inline">\(m=10000000\)</span>)</p></li>
<li><p>Implementation (see <a href="../../DL/ANN/#gd">gradient descent</a> for more details)</p>
<p><span class="math display">\[\begin{align}
  \mathcal{L}(\hat{Y},Y)&amp;=\frac{1}{2}\sum_{i=1}^{m&#39;}{(\hat{Y_i}-Y_i)^2} \\
  W&amp;=W-\alpha\frac{\partial\mathcal{L}}{\partial W}
  \end{align}\]</span></p></li>
<li><p>Performance</p>
<ul>
<li>BGD vs MBGD</li>
</ul>
<center>
<p><img src="../../images/DL/bgdvsmbgd.png" width="500"/></p>
</center>
<ul>
<li><p>BGD vs SGD</p>
<center>
<p><img src="../../images/DL/bgdvssgd.png" width="400"/></p>
</center>
<p><br/>
BGD: large steps, low noise, too long per iteration<br />
SGD: small steps, insane noise, lose vectorization<br />
MBGD: in between <span class="math inline">\(\rightarrow\)</span> optimal in most cases</p></li>
</ul></li>
</ul>
<p><br/>
<strong>Gradient Descent with Momentum</strong></p>
<ul>
<li><p><a name="ema"></a><strong>Exponentially Weighted (Moving) Average</strong></p>
<ul>
<li><p>Intuition</p>
<center>
<p><img src="../../images/DL/ema.png" width="500"/></p>
</center>
<p><br/>
The blue dots represent the raw data points, while the red and green curves represent the two EMAs of the blue dots. As clearly indicated by the figure, EMA is used to reduce the huge oscillation of such time-series data.</p></li>
<li><p>Formula</p>
<p><span class="math display">\[\begin{equation}
  V_t=\beta V_{t-1}+(1-\beta)\theta_t
  \end{equation}\]</span></p>
<ul>
<li><p><span class="math inline">\(\theta_t\)</span>: the original time-series data point at time <span class="math inline">\(t\)</span></p></li>
<li><p><span class="math inline">\(V_t\)</span>: the EMA data point at time <span class="math inline">\(t\)</span></p></li>
<li><p><span class="math inline">\(\beta\)</span>: an indicator of how many time units (e.g. days) this algorithm is approximately averaging over:</p>
<p><span class="math display">\[\begin{equation}
  \text{#time units}=\frac{1}{1-\beta}
  \end{equation}\]</span></p>
<p>e.g. <span class="math inline">\(\beta=0.9 \rightarrow\)</span> average over 10 days; <span class="math inline">\(\beta=0.96 \rightarrow\)</span> average over 25 days</p></li>
</ul></li>
<li><p>Performance: easy computation + one-line code + memory efficiency</p></li>
<li><p><a name="bc"></a><strong>Bias Correction</strong></p>
<p>Assume <span class="math inline">\(\beta=0.99\)</span>:</p>
<p><span class="math display">\[\begin{align}
  &amp;V_0=0 \\
  &amp;V_1=0.99 V_0+0.01\theta_1=0.01\theta_1 \\
  &amp;V_2=0.99 V_2+0.01\theta_2=0.099\theta_1+0.01\theta_2 \\
  &amp;...
  \end{align}\]</span></p>
<p>Notice that <span class="math inline">\(V_1 \&amp; V_2\)</span> are very tiny portions of <span class="math inline">\(\theta_1 \&amp; \theta_2\)</span>, meaning that they do not accurately represent the actual data points.</p>
<p>Thus, it is necessary to rescale the early EMA values, with the following formula:</p>
<p><span class="math display">\[\begin{equation}
  V_t:=\frac{V_t}{1-\beta^t}
  \end{equation}\]</span></p>
<p>In the later calculations, bias correction is not so necessary.</p></li>
</ul></li>
<li><p><a name="m"></a><strong>Momentum</strong>: application of EMA in GD</p>
<ol style="list-style-type: decimal">
<li><p>Compute <span class="math inline">\(dW,db\)</span> on the current MB</p></li>
<li><p>Compute EMA</p>
<p><span class="math display">\[\begin{align}
 &amp;V_{dW}:=\beta V_{dW}+(1-\beta)dW \\
 &amp;V_{db}:=\beta V_{db}+(1-\beta)db
 \end{align}\]</span></p></li>
<li><p>Compute GD</p>
<p><span class="math display">\[\begin{align}
 &amp;W:=W-\alpha V_{dW} \\
 &amp;b:=b-\alpha V_{db}
 \end{align}\]</span></p></li>
</ol>
<p><span class="math inline">\(\beta\)</span> is often chosen as <span class="math inline">\(0.9\)</span> in GD with Momentum.</p>
<p>Why named “momentum?” Think of <span class="math inline">\(dW\)</span> as acceleration, <span class="math inline">\(V_{dW}\)</span> as velocity, and <span class="math inline">\(\beta\)</span> as friction.</p></li>
<li><p>Performance</p>
<center>
<p><img src="../../images/DL/momentum.png" width="500"/></p>
</center>
<p>Red steps represent Momentum, while blue steps represent normal GD.</p>
<p>Slower learning vertically + Faster learning horizontally</p>
<p><span class="math inline">\(\rightarrow\)</span> Momentum is always better than SGD</p></li>
</ul>
<p><br/>
<a name="rmsprop"></a><strong>RMSprop (Root Mean Square Propagation)</strong></p>
<ul>
<li><p>Intuition: a modified version of GD with Momentum</p>
<p>Why? To further minimize the oscillation of GD and maximize the speed of convergence.</p></li>
<li><p>Steps:</p>
<ol style="list-style-type: decimal">
<li><p>Compute <span class="math inline">\(dW,db\)</span> on the current MB</p></li>
<li><p>Compute RMS step</p>
<p><span class="math display">\[\begin{align}
 &amp;S_{dW}:=\beta S_{dW}+(1-\beta)dW^2 \\
 &amp;S_{db}:=\beta S_{db}+(1-\beta)db^2
 \end{align}\]</span></p>
<p>where <span class="math inline">\(dW^2=dW* dW\)</span></p></li>
<li><p>Compute GD</p>
<p><span class="math display">\[\begin{align}
 &amp;W:=W-\alpha \frac{dW}{\sqrt{S_{dW}}+\varepsilon} \\
 &amp;b:=b-\alpha \frac{db}{\sqrt{S_{db}}+\varepsilon}
 \end{align}\]</span></p></li>
</ol>
<p><span class="math inline">\(\varepsilon\)</span> is added to ensure <span class="math inline">\(\text{denominator}\neq0\)</span> (normally <span class="math inline">\(\varepsilon=10^{-8}\)</span>)</p></li>
</ul>
<p><br/>
<a name="adam"></a><strong>Adam</strong></p>
<ul>
<li><p>Intuition: <strong>Momentum + RMSprop</strong></p></li>
<li><p>Steps:</p>
<ol style="list-style-type: decimal">
<li><p>Compute <span class="math inline">\(dW,db\)</span> on the current MB</p></li>
<li><p>Compute Momentum:</p>
<p><span class="math display">\[\begin{align}
 &amp;V_{dW}:=\beta_1 V_{dW}+(1-\beta_1)dW \\
 &amp;V_{db}:=\beta_1 V_{db}+(1-\beta_1)db
 \end{align}\]</span></p>
<p>Compute RMSprop:</p>
<p><span class="math display">\[\begin{align}
 &amp;S_{dW}:=\beta_2 S_{dW}+(1-\beta_2)dW^2 \\
 &amp;S_{db}:=\beta_2 S_{db}+(1-\beta_2)db^2
 \end{align}\]</span></p></li>
<li><p>Bias Correction:</p>
<p><span class="math display">\[\begin{align}
 &amp;V_{dW}:=\frac{V_{dW}}{1-\beta_1^t}, V_{db}:=\frac{V_{db}}{1-\beta_1^t} \\
 &amp;S_{dW}:=\frac{S_{dW}}{1-\beta_2^t}, S_{db}:=\frac{S_{db}}{1-\beta_2^t}
 \end{align}\]</span></p></li>
<li><p>Compute GD:</p>
<p><span class="math display">\[\begin{align}
 &amp;W:=W-\alpha \frac{V_{dW}}{\sqrt{S_{dW}}+\varepsilon} \\
 &amp;b:=b-\alpha \frac{V_{db}}{\sqrt{S_{db}}+\varepsilon}
 \end{align}\]</span></p>
<p>Hyperparameter choices:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span>: depends</li>
<li><span class="math inline">\(\beta_1: 0.9\)</span></li>
<li><span class="math inline">\(\beta_2: 0.999\)</span></li>
<li><span class="math inline">\(\varepsilon: 10^{-8}\)</span></li>
</ul></li>
</ol></li>
</ul>
<p><br/>
<a name="lrd"></a><strong>Learning Rate Decay</strong></p>
<ul>
<li><p>Intuition: as <span class="math inline">\(\alpha\)</span> slowly decreases, training steps become smaller <span class="math inline">\(\rightarrow\)</span> oscillating closely around the minimum (instead of jumping over the minimum)</p></li>
<li><p>Main Method:</p>
<p><span class="math display">\[\begin{equation}
  \alpha=\frac{1}{1+r_{\text{decay}}\cdot \text{#epoch}}\cdot\alpha_0
  \end{equation}\]</span></p>
<p>where 1 epoch means passing through data once.</p>
<p>Normally, <span class="math inline">\(\alpha_0=0.2,r_{\text{decay}}=1\)</span></p></li>
<li><p>Other Methods:</p>
<ul>
<li><p>Exponential Decay:</p>
<p><span class="math display">\[\begin{equation}
  \alpha=0.95^{\text{#epoch}}\cdot\alpha_0
  \end{equation}\]</span></p></li>
<li><p>Root Decay:</p>
<p><span class="math display">\[\begin{equation}
  \alpha=\frac{k}{\sqrt{\text{#epoch}}}\cdot\alpha_0
  \end{equation}\]</span></p></li>
<li><p>Discrete Staircase:</p>
<center>
<p><img src="../../images/DL/staircase.png" width="150"/></p>
</center></li>
<li><p>Manual Decay</p></li>
</ul></li>
</ul>
<p><br/>
<a name="po"></a><strong>Problems with optimization</strong></p>
<p>As learnt in Calculus, no matter how we try to find the optimum, we always have problems:</p>
<ul>
<li>Local Optima: we get stuck in local optima instead of moving to global optima</li>
<li>Saddle Points: we find GD=0 at saddle points before we find global optima</li>
<li>Plateau: long saddle that makes learning super slow</li>
</ul>
</div>
<div id="hyperparameter-tuning" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Hyperparameter Tuning</h2>
<p><strong>Intuition</strong>: try to find the optimal hyperparameter for the NN</p>
<p><strong>List of Hyperparameters</strong> (in the order of priority)
- Tier 1: <span class="math inline">\(\alpha\)</span>
- Tier 2: #hidden units, MB size
- Tier 3: #layers, <span class="math inline">\(\alpha\)</span> decay
- Tier 4: <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>, <span class="math inline">\(\varepsilon\)</span></p>
<p><strong>Random Picking</strong>: e.g. <span class="math inline">\(n^{[l]}\in \[50,100\], L\in \[2,4\]\)</span></p>
<p><strong>Appropriate Scale</strong>: e.g. <span class="math inline">\(\alpha\in \[0.0001,1\]\)</span> is obviously NOT an appropriate scale, because 90% of the values are in <span class="math inline">\(\[0.1,1\]\)</span>.</p>
<p>Instead, <span class="math inline">\(\alpha\in\[0.0001,1\]_ {\text{log}}\)</span> is an appropriate scales because the random picking is equally distributed on the log scale.</p>
<p>e.g. for <span class="math inline">\(\beta\in\[0.9,0.999\]\)</span>, the code implementation should be
- <span class="math inline">\(r\in\[-3,-1\]\)</span>
- <span class="math inline">\(\beta=1-10^r\)</span></p>
</div>
<div id="batch-normalization" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Batch Normalization</h2>
<p><strong>Intuition</strong>: Feature scaling normalizes the inputs to speed up learning for the 1st layer. Similarly, can we normalize <span class="math inline">\(a^{\[l-1\]}\)</span> to train <span class="math inline">\(W^{\[l\]} \&amp; b^{\[l\]}\)</span> faster? Obviously.</p>
<p><strong>Implementation</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>Calculate mean &amp; variance</p>
<p><span class="math display">\[\begin{align}
 \mu&amp;=\frac{1}{m}\sum_{i=1}^{m}{z^{[l](i)}} \\
 \sigma^2&amp;=\frac{1}{m}\sum_{i=1}^{m}{(z^{[l](i)}-\mu)^2}
 \end{align}\]</span></p></li>
<li><p>Normalize Node Output:</p>
<p><span class="math display">\[\begin{equation}
 z_{\text{norm}}^{[l](i)}=\gamma\frac{z^{[l](i)}-\mu}{\sqrt{\sigma^2+\varepsilon}}+\beta
 \end{equation}\]</span></p>
<ul>
<li><span class="math inline">\(\gamma\ \&amp;\ \beta\)</span> = learnable parameters</li>
<li><span class="math inline">\(\gamma\neq\sqrt{\sigma^2+\varepsilon}\)</span> and <span class="math inline">\(\beta\neq\mu\)</span></li>
<li>Make sure to add <span class="math inline">\(\gamma\ \&amp;\ \beta\)</span> to the dictionary of parameter updates during coding</li>
<li>Batch Normalization eliminates <span class="math inline">\(b^{[l]}\)</span> during <span class="math inline">\(\mu\)</span> calculation</li>
</ul></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cnn.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jules32/bookdown-tutorial/edit/master/02_improvements.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["series.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
