<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1 Mean Models | Time Series Analysis</title>
  <meta name="description" content="1 Mean Models | Time Series Analysis" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1 Mean Models | Time Series Analysis" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="MrQ02/tsa" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 Mean Models | Time Series Analysis" />
  
  
  

<meta name="author" content="Renyi Qu" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="v.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Time Series Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="1" data-path="m.html"><a href="m.html"><i class="fa fa-check"></i><b>1</b> Mean Models</a>
<ul>
<li class="chapter" data-level="1.1" data-path="m.html"><a href="m.html#ar-autoregressive-model"><i class="fa fa-check"></i><b>1.1</b> AR (Autoregressive model)</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="m.html"><a href="m.html#model"><i class="fa fa-check"></i><b>1.1.1</b> Model</a></li>
<li class="chapter" data-level="1.1.2" data-path="m.html"><a href="m.html#estimation"><i class="fa fa-check"></i><b>1.1.2</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="m.html"><a href="m.html#ma-moving-average-model"><i class="fa fa-check"></i><b>1.2</b> MA (Moving Average model)</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="m.html"><a href="m.html#model-1"><i class="fa fa-check"></i><b>1.2.1</b> Model</a></li>
<li class="chapter" data-level="1.2.2" data-path="m.html"><a href="m.html#estimation-1"><i class="fa fa-check"></i><b>1.2.2</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="m.html"><a href="m.html#arma-autoregressive-moving-average-model"><i class="fa fa-check"></i><b>1.3</b> ARMA (Autoregressive Moving Average model)</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="m.html"><a href="m.html#model-2"><i class="fa fa-check"></i><b>1.3.1</b> Model</a></li>
<li class="chapter" data-level="1.3.2" data-path="m.html"><a href="m.html#estimation-2"><i class="fa fa-check"></i><b>1.3.2</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="m.html"><a href="m.html#arima-autoregressive-integrated-moving-average-model"><i class="fa fa-check"></i><b>1.4</b> ARIMA (Autoregressive Integrated Moving Average model)</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="m.html"><a href="m.html#model-3"><i class="fa fa-check"></i><b>1.4.1</b> Model</a></li>
<li class="chapter" data-level="1.4.2" data-path="m.html"><a href="m.html#estimation-3"><i class="fa fa-check"></i><b>1.4.2</b> Estimation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="v.html"><a href="v.html"><i class="fa fa-check"></i><b>2</b> Volatility models</a>
<ul>
<li class="chapter" data-level="2.1" data-path="v.html"><a href="v.html#arch-autoregressive-conditional-heteroskedasticity-model"><i class="fa fa-check"></i><b>2.1</b> ARCH (Autoregressive Conditional Heteroskedasticity model)</a></li>
<li class="chapter" data-level="2.2" data-path="v.html"><a href="v.html#garch-generalized-autoregressive-conditional-heteroskedasticity-model"><i class="fa fa-check"></i><b>2.2</b> GARCH (Generalized Autoregressive Conditional Heteroskedasticity model)</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="v.html"><a href="v.html#estimation-4"><i class="fa fa-check"></i><b>2.2.1</b> Estimation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="cnn.html"><a href="cnn.html"><i class="fa fa-check"></i><b>3</b> Convolutional Neural Networks</a>
<ul>
<li class="chapter" data-level="3.1" data-path="cnn.html"><a href="cnn.html#basics-of-cnn"><i class="fa fa-check"></i><b>3.1</b> Basics of CNN</a></li>
<li class="chapter" data-level="3.2" data-path="cnn.html"><a href="cnn.html#cnn-examples"><i class="fa fa-check"></i><b>3.2</b> CNN Examples</a></li>
<li class="chapter" data-level="3.3" data-path="cnn.html"><a href="cnn.html#object-detection"><i class="fa fa-check"></i><b>3.3</b> Object Detection</a></li>
<li class="chapter" data-level="3.4" data-path="cnn.html"><a href="cnn.html#face-recognition"><i class="fa fa-check"></i><b>3.4</b> Face Recognition</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Time Series Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="m" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Mean Models</h1>
<div id="ar-autoregressive-model" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> AR (Autoregressive model)</h2>
<div id="model" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Model</h3>
<p><strong>AR(p) - General</strong>:</p>
<p><span class="math display">\[\begin{equation*} x_t=\alpha_0+\sum_{i=1}^{p}{\alpha_i x_{t-i}}+\varepsilon_t
\end{equation*}\]</span></p>
<ul>
<li><span class="math inline">\(x_t\)</span>: time series to be modeled</li>
<li><span class="math inline">\(x_{t-i}\)</span>: past time series values</li>
<li><span class="math inline">\(p\)</span>: lag limit</li>
<li><span class="math inline">\(\alpha_i\)</span>: params to be estimated</li>
<li><span class="math inline">\(\varepsilon_t \sim N(0,\sigma^2)\)</span>: i.i.d. white noise</li>
</ul>
<p>
 
</p>
<p><strong>AR(p) - Markovian</strong>:</p>
<p><span class="math display">\[\begin{align*}
        p(y_{1:T})&amp;=p(y_{1:p})\prod_{t=p+1}^{T}{p(y_t|y_{(t-p):(t-1)})}\\
        p(\boldsymbol{y}|y_{1:p})&amp;=\prod_{t=p+1}^{T}{p(y_t|y_{(t-p):(t-1)})}\\
        &amp;=\prod_{t=p+1}^{T}{N(y_t|\boldsymbol{f}_t^\prime\boldsymbol{\phi},v)}\\
        &amp;=N(\boldsymbol{y}|\boldsymbol{F}^\prime\boldsymbol{\phi},v\boldsymbol{I}_n)
    \end{align*}\]</span></p>
<ul>
<li><span class="math inline">\(T=n+p\)</span></li>
<li><span class="math inline">\(\phi=(\phi_1,\cdots,\phi_p)\)</span></li>
<li><span class="math inline">\(\boldsymbol{f}_t=(y_{t-1},\cdots,y_{t-p})\)</span></li>
<li><span class="math inline">\(\boldsymbol{F}=[\boldsymbol{f}_T,\cdots,\boldsymbol{f}_{p+1}]\)</span></li>
</ul>
<p>
 
</p>
<p><strong>AR(p) - State-space</strong>:</p>
<p><span class="math display">\[\begin{align*}
        y_t&amp;=\boldsymbol{F}^\prime\boldsymbol{x}_t\\
        \boldsymbol{x}_t&amp;=\boldsymbol{G}\boldsymbol{x}_{t-1}+\boldsymbol{\omega}_t
    \end{align*}\]</span></p>
<ul>
<li><span class="math inline">\(\boldsymbol{x}_t=(y_t,\cdots,y_{t-p+1})\)</span>: state vector</li>
<li><span class="math inline">\(\boldsymbol{\omega}_t=(\epsilon_t,0,\cdots,0)\)</span>: error vector</li>
<li><span class="math inline">\(\boldsymbol{F}=(1,0,\cdots,0)\)</span></li>
<li><span class="math inline">\(\boldsymbol{G}=\begin{bmatrix}\phi_1 &amp; \phi_2 &amp; \cdots &amp; \phi_{p-1} &amp; \phi_p \\ 1 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; \cdots &amp; 0 &amp; 0 \\ \vdots &amp; &amp; \ddots &amp; 0 &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; 1 &amp; 0\end{bmatrix}\)</span></li>
</ul>
<p>
 
</p>
<p><strong>AR(p) - Autoorrelation</strong>:</p>
<p><span class="math display">\[\begin{align*}
        &amp;\rho(h)-\sum_{i=1}^{p}{\phi_i\rho(h-i)}=0\\
        &amp;\rho(h)=\sum_{j=1}^{r}{\alpha_j^hp_j(h)}
    \end{align*}\]</span></p>
<ul>
<li><span class="math inline">\(\alpha_1,\cdots,\alpha_r\)</span>: reciprocal roots of characteristic polynomial</li>
<li><span class="math inline">\(m_1,\cdots,m_r\)</span>: root multiplicity (<span class="math inline">\(\sum_{i=1}^r{m_i}=p\)</span>)</li>
<li><span class="math inline">\(p_j(h)\)</span>: polynomial of degree <span class="math inline">\(m_j-1\)</span></li>
</ul>
<p>
 
</p>
</div>
<div id="estimation" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Estimation</h3>
<p><strong>LSE - AR(1)</strong>:</p>
<p><span class="math display">\[\begin{align*}
        \hat{\alpha}_{ols}&amp;=\mathop{\mathrm{argmin}}_{\alpha}{\sum_{t=1}^{T}{(x_t-\alpha x_{t-1})^2}}\\
        &amp;=\bigg(\sum_{t=1}^{T}{x_{t-1}^2}\bigg)^{-1}\bigg(\sum_{t=1}^{T}{x_{t-1}x_t}\bigg)
    \end{align*}\]</span></p>
<p>
 
</p>
<p><strong>MLE - AR(1)</strong>:</p>
<ul>
<li>Conditional likelihood:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
        \mathcal{L}(\boldsymbol{x|x_{-1}})=\bigg(\frac{1}{\sqrt{2\pi}\sigma}\bigg)^T\exp{\bigg(-\frac{1}{2\sigma^2}\sum_{t=1}^{T}{(x_t-\alpha x_{t-1})^2}\bigg)}
    \end{equation*}\]</span></p>
<ul>
<li>Conditional log likelihood:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
        l(\boldsymbol{x|x_{-1}})=-T\log{\sqrt{2\pi}\sigma}-\frac{1}{2\sigma^2}\sum_{t=1}^{T}{(x_t-\alpha x_{t-1})^2}
    \end{equation*}\]</span></p>
<ul>
<li>Conditional ML estimator:</li>
</ul>
<p><span class="math display">\[\begin{align*}
        \hat{\alpha}_{ml}&amp;=\mathop{\mathrm{argmax}}_\alpha{l(\boldsymbol{x|x_{-1}})} \\
        &amp;=\mathop{\mathrm{argmax}}_\alpha{\bigg(-\sum_{t=1}^{T}{(x_t-\alpha x_{t-1})^2}\bigg)} \\
        &amp;=\mathop{\mathrm{argmin}}_\alpha{\sum_{t=1}^{T}{(x_t-\alpha x_{t-1})^2}} \\
    \end{align*}\]</span></p>
<p>
 
</p>
</div>
</div>
<div id="ma-moving-average-model" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> MA (Moving Average model)</h2>
<div id="model-1" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Model</h3>
<p><strong>MA(q)</strong>:</p>
<p><span class="math display">\[\begin{equation*}
        x_t=\mu+\sum_{i=1}^{q}{\beta_i \varepsilon_{t-i}}+\varepsilon_t
    \end{equation*}\]</span></p>
<ul>
<li><span class="math inline">\(\mu\)</span>: mean of <span class="math inline">\(x_t\)</span></li>
<li><span class="math inline">\(\varepsilon_{t-i}\)</span>: past error values</li>
<li><span class="math inline">\(q\)</span>: lag limit</li>
<li><span class="math inline">\(\beta_i\)</span>: params to be estimated</li>
<li><span class="math inline">\(\varepsilon_t\)</span>: unobservable white noise at the current time</li>
</ul>
<p>
 
</p>
</div>
<div id="estimation-1" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Estimation</h3>
<p><strong>LSE - MA(1)</strong>:</p>
<p><span class="math display">\[\begin{equation*}
        \hat{\beta}_{ols}=\mathop{\mathrm{argmin}}_\beta{\sum_{t=1}^T{(x_t-\beta\varepsilon_{t-1})^2}}
    \end{equation*}\]</span></p>
<p>How to deal with unknown random disturbances:</p>
<p><span class="math display">\[\begin{align*}
        &amp;\varepsilon_1=x_1-\beta\varepsilon_0 \\
        &amp;\varepsilon_2=x_2-\beta(x_1-\beta\varepsilon_0) \\
        &amp;\varepsilon_3=x_3-\beta(x_2-\beta(x_1-\beta\varepsilon_0)) \\
        
&amp;\varepsilon_{t-1}=(-\beta)^{t-1}\varepsilon_0+\sum_{k=0}^{t-2}{(-\beta)^kx_{t-1-k}}\end{align*}\]</span></p>
<p>Thus, we obtain the Nonlinear LS estimator:</p>
<p><span class="math display">\[\begin{equation*}
        \hat{\beta}_{nls}=\mathop{\mathrm{argmin}}_{\beta}{\sum_{t=1}^{T}{\bigg(x_t-\beta\sum_{k=0}^{t-2}{(-\beta)^kx_{t-1-k}}\bigg)^2}}
    \end{equation*}\]</span></p>
<p>
 
</p>
<p><strong>MLE - MA(1)</strong>:</p>
<p>How to deal with unknown random disturbances:</p>
<p><span class="math display">\[\begin{align*}
        &amp;\mathcal{L}(x_1)=\frac{1}{\sqrt{2\pi}\sigma}\exp{\bigg(-\frac{\varepsilon_1^2}{2\sigma^2}\bigg)} \\
        &amp;\mathcal{L}(x_2|x_1)=\frac{1}{\sqrt{2\pi}\sigma}\exp{\bigg(-\frac{(x_2-\beta\varepsilon_1)^2}{2\sigma^2}\bigg)}=\frac{1}{\sqrt{2\pi}\sigma}\exp{\bigg(-\frac{\varepsilon_2^2}{2\sigma^2}\bigg)} \\
        &amp;\cdots \\
        &amp;\mathcal{L}(x_t|x_{t-1},\cdots,x_1)=\frac{1}{\sqrt{2\pi}\sigma}\exp{\bigg(-\frac{(x_t-\beta\varepsilon_{t-1})^2}{2\sigma^2}\bigg)}\\
        &amp;=\frac{1}{\sqrt{2\pi}\sigma}\exp{\bigg(-\frac{\varepsilon_t^2}{2\sigma^2}\bigg)}
    \end{align*}\]</span></p>
<ul>
<li>Conditional likelihood:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
        \mathcal{L}(\boldsymbol{x|x_{-1}})=\bigg(\frac{1}{\sqrt{2\pi}\sigma}\bigg)^T\exp{\bigg(-\frac{1}{2\sigma^2}\sum_{t=1}^T{\varepsilon_t^2}\bigg)}
    \end{equation*}\]</span></p>
<ul>
<li>Conditional log likelihood:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
        l(\boldsymbol{x|x_{-1}})=-T\log{\sqrt{2\pi}\sigma}-\frac{1}{2\sigma^2}\sum_{t=1}^T{\varepsilon_t^2}
    \end{equation*}\]</span></p>
<ul>
<li>Conditional ML estimator:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
        \hat{\beta}_{ml}=\mathop{\mathrm{argmax}}_\beta{l(\boldsymbol{x|x_{-1}})}=\mathop{\mathrm{argmin}}_\beta{\sum_{t=1}^T{\varepsilon_t^2}}
    \end{equation*}\]</span></p>
<p>
 
</p>
</div>
</div>
<div id="arma-autoregressive-moving-average-model" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> ARMA (Autoregressive Moving Average model)</h2>
<div id="model-2" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Model</h3>
<p><strong>ARMA(p,q) - General</strong>:</p>
<p><span class="math display">\[\begin{equation*}
        x_t=\alpha_0+\sum_{i=1}^{p}{\alpha_i x_{t-i}}+\sum_{i=1}^{q}{\beta_i \varepsilon_{t-i}}+\varepsilon_t
    \end{equation*}\]</span></p>
<ul>
<li>Explanatory variables: <span class="math inline">\(x_{t-i}\ \&amp;\ \varepsilon_{t-i}\)</span></li>
<li>Parameters: <span class="math inline">\(\alpha_i\ \&amp;\ \beta_i\)</span></li>
<li>Hyperparameters: <span class="math inline">\(p\ \&amp;\ q\)</span></li>
<li>Random disturbance: <span class="math inline">\(\varepsilon_t\)</span></li>
</ul>
<p>
 
</p>
<p><strong>ARMA(p,q) - State-space</strong>:</p>
<p><span class="math display">\[\begin{align*}
        y_t&amp;=\boldsymbol{E}_m^\prime\boldsymbol{\theta}_t\\
        \boldsymbol{\theta}_t&amp;=\boldsymbol{G}\boldsymbol{\theta}_{t-1}+\boldsymbol{\omega}_t
    \end{align*}\]</span></p>
<ul>
<li><span class="math inline">\(\boldsymbol{E}_m=(1,0,\cdots,0)\)</span>, shape <span class="math inline">\(m=\max{(p,q+1)}\)</span></li>
<li><span class="math inline">\(\boldsymbol{\omega}_t=(1,\theta_1,\cdots,\theta_{m-1})\epsilon_t\)</span></li>
<li><span class="math inline">\(\boldsymbol{G}=\begin{bmatrix}\phi_1 &amp; \phi_2 &amp; \cdots &amp; \phi_{m-1} &amp; \phi_m \\ 1 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; \cdots &amp; 0 &amp; 0 \\ \vdots &amp; &amp; \ddots &amp; 0 &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; 1 &amp; 0\end{bmatrix}\)</span></li>
</ul>
<p>
 
</p>
</div>
<div id="estimation-2" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Estimation</h3>
<p><strong>LSE - ARMA(p,q)</strong>:</p>
<ul>
<li><p>Minimize:</p>
<p><span class="math display">\[\begin{equation*}
      S(\boldsymbol{\theta})=\sum_{t=1}^{T}{\frac{(y_t-y_t^{t-1})^2}{r_t^{t-1}}}
  \end{equation*}\]</span></p>
<ul>
<li><span class="math inline">\(\boldsymbol{\theta}=(\alpha_1,\cdots,\alpha_p,\beta_1,\cdots,\beta_q)\)</span>: parameter set</li>
</ul></li>
<li><p>Conditional LS:</p>
<p><span class="math display">\[\begin{equation*}
      S_c(\boldsymbol{\theta})=\sum_{t=p+1}^T{\epsilon_t(\boldsymbol{\theta})^2}
  \end{equation*}\]</span></p>
<ul>
<li><span class="math inline">\(\epsilon_t(\boldsymbol{\theta})=y_t-\hat{y}_t\)</span></li>
</ul></li>
</ul>
<p>
 
</p>
<p><strong>MLE - ARMA(p,q)</strong>:</p>
<ul>
<li>Conditional likelihood:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
        p(y_{1:T}|\boldsymbol{\theta},v)=\prod_{t=1}^T{p(y_t|y_{1:(t-1)},\boldsymbol{\theta},v)}
    \end{equation*}\]</span></p>
<ul>
<li><p>Conditional log likelihood:</p>
<p><span class="math display">\[\begin{equation*}
      \log{p(y_{1:T}|\boldsymbol{\theta},v)}=-\frac{T}{2}\log{2\pi v}-\frac{1}{2}\sum_{t=1}^T{\Big(\log{r_t^{t-1}}+\frac{(y_t-y_t^{t-1})^2}{r_t^{t-1}}\Big)}
  \end{equation*}\]</span></p>
<ul>
<li><span class="math inline">\(y_t^{t-1}=\text{E}[y_t|y_{1:(t-1)}]\)</span></li>
<li><span class="math inline">\(vr_t^{t-1}=\text{Var}[y_t|y_{1:(t-1)}]\)</span></li>
</ul></li>
</ul>
<p>
 
</p>
<p><strong>Bayesian - ARMA(p,q)</strong>:</p>
<p>Likelihood based on parameters:</p>
<p><span class="math display">\[\begin{equation*}
        p(y_{1:T}|\boldsymbol{\varphi})=\big(\frac{1}{\sqrt{2\pi v}}\big)^T\exp{\bigg(-\frac{1}{2v}\sum_{t=1}^T{(y_t-\mu_t)^2}\bigg)}
    \end{equation*}\]</span></p>
<ul>
<li><span class="math inline">\(\boldsymbol{\varphi}=(\boldsymbol{\alpha},\boldsymbol{\beta},v,\boldsymbol{x}_0,\boldsymbol{\epsilon}_0)\)</span></li>
<li><span class="math inline">\(\boldsymbol{\epsilon}_0=(\epsilon_0,\epsilon_{-1},\cdots,\epsilon_{1-q})\)</span></li>
<li><span class="math inline">\(\mu_1=\sum_{i=1}^p{\alpha_iy_{1-i}}+\sum_{i=1}^q{\beta_i\epsilon_{1-i}}\)</span></li>
<li><span class="math inline">\(\mu_t=\sum_{i=1}^p{\alpha_iy_{t-i}}+\sum_{i=1}^{t-1}{\beta_i(y_{t-i}-\mu_{t-i})}+\sum_{i=1}^q{\beta_i\epsilon_{t-i}},t=2:q\)</span></li>
<li><span class="math inline">\(\mu_t=\sum_{i=1}^p{\alpha_iy_{t-i}}+\sum_{i=1}^{t-1}{\beta_i(y_{t-i}-\mu_{t-i})},t=q+1:T\)</span></li>
</ul>
<p>
 
</p>
<p>Prior:</p>
<p><span class="math display">\[\begin{equation*}
        \pi(\boldsymbol{\varphi})=\pi(\boldsymbol{x}_0,\boldsymbol{\epsilon}_0|\boldsymbol{\alpha},\boldsymbol{\beta},v)\pi(v)\pi(\boldsymbol{\alpha},\boldsymbol{\beta})
    \end{equation*}\]</span></p>
<ul>
<li><span class="math inline">\(\pi(\boldsymbol{x}_0,\boldsymbol{\epsilon}_0|\boldsymbol{\alpha},\boldsymbol{\beta},v)=N(\boldsymbol{0},v\Omega)\)</span></li>
<li><span class="math inline">\(\pi(v)\propto\frac{1}{v}\)</span></li>
<li><span class="math inline">\(\pi(\boldsymbol{\alpha},\boldsymbol{\beta})\)</span>: uniform distribution</li>
<li><span class="math inline">\(v\Omega=\text{Cov}[\boldsymbol{x}_0,\boldsymbol{\epsilon}_0]\)</span></li>
</ul>
<p>
 
</p>
<p>Joint Posterior:</p>
<p><span class="math display">\[\begin{equation*}
        p(\boldsymbol{\varphi}|y_{1:T})\propto (v)^{-\frac{T+2}{2}}\exp{-\frac{1}{2v}\sum_{t=1}^T{(y_t-\mu_t)^2}}\times N((\boldsymbol{x}_0,\boldsymbol{\epsilon}_0)|\boldsymbol{0},v\Omega)
    \end{equation*}\]</span></p>
<p>
 
</p>
<p>MCMC:</p>
<ul>
<li>Sample <span class="math inline">\((v|\boldsymbol{\alpha},\boldsymbol{\beta},\boldsymbol{x}_0,\boldsymbol{\epsilon}_0)\)</span> from inverse-gamma full conditional distribution:</li>
<li>Sample <span class="math inline">\((\boldsymbol{x}_0,\boldsymbol{\epsilon}_0|\boldsymbol{\alpha},\boldsymbol{\beta},v)\)</span> using a Metropolis step with Gaussian proposal distributions</li>
<li>Sample <span class="math inline">\((\boldsymbol{\alpha},\boldsymbol{\beta}|v,\boldsymbol{x}_0,\boldsymbol{\epsilon}_0)\)</span> from PACF</li>
</ul>
<p>
 
</p>
</div>
</div>
<div id="arima-autoregressive-integrated-moving-average-model" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> ARIMA (Autoregressive Integrated Moving Average model)</h2>
<div id="model-3" class="section level3" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Model</h3>
<p><strong>Differencing</strong>:</p>
<p><span class="math display">\[\begin{align*}
    &amp;x^{(1)}_t=x_t-x_{t-1}\\
    &amp;x^{(2)}_t=x^{(1)}_t-x^{(1)}_{t-1}\\
    &amp;\cdots\\
    &amp;x^{(d)}_t=x^{(d-1)}_t-x^{(d-1)}_{t-1}
\end{align*}\]</span></p>
<p><strong>ARIMA(p,d,q)</strong>:</p>
<p><span class="math display">\[\begin{equation*}
    \Phi(L)(1-L)^dx_t=\Theta(L)\varepsilon_t
\end{equation*}\]</span></p>
<ul>
<li>AR operator: <span class="math inline">\(\Phi(L)=1-\sum_{i=1}^{p}{\alpha_iL^i}\)</span></li>
<li>MA operator: <span class="math inline">\(\Theta(L)=1+\sum_{i=1}^{q}{\beta_iL^i}\)</span></li>
</ul>
<p>
 
</p>
</div>
<div id="estimation-3" class="section level3" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Estimation</h3>
<p><strong>LSE - ARIMA(p,1,q)</strong>:</p>
<ul>
<li><p>Parameter Collection: <span class="math inline">\(\boldsymbol{\theta}=(\alpha_0,\alpha_1,\cdots,\alpha_p,\beta_1,\cdots,\beta_q)\)</span></p></li>
<li><p>Independent Variable Collection: <span class="math inline">\(\boldsymbol{\omega}_t=(1,z_{t-1},\cdots,z_{t-p},\hat{\varepsilon}_{t-1},\cdots,\hat{\varepsilon}_{t-q})\)</span></p></li>
<li><p>:</p></li>
</ul>
<p><span class="math display">\[\begin{equation*}
        z_t=\boldsymbol{\theta}^T\boldsymbol{\omega}_t+\varepsilon_t
    \end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
        \hat{\boldsymbol{\theta}}_{ols}=\mathop{\mathrm{argmin}}_{\boldsymbol{\theta}}{\sum_{t=2}^{T}{(z_t-\boldsymbol{\theta}^T\boldsymbol{\omega}_t)^2}}
    \end{equation*}\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="v.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jules32/bookdown-tutorial/edit/master/01_mean.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["series.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
